{"block_file": {"custom/dt_trainer.py:custom:python:dt trainer": {"content": "from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, data_2, *args, **kwargs):\n    if \"dt\" not in data_2:\n        # return \"Decision tree model isn't being trained.\"\n        return None\n\n\n    X_train, X_validation, y_train, y_test = data\n\n    dt = GridSearchCV(DecisionTreeRegressor(random_state=0), data_2.get(\"dt\"), cv=5)\n    dt.fit(X_train, y_train)\n    dt_pred = dt.predict(X_validation)\n    dt_rmse = np.sqrt(mean_squared_error(y_test, dt_pred))\n\n    return {\"model\": \"dt\", \"rmse\": dt_rmse, \"trained_model\": dt}\n\n", "file_path": "custom/dt_trainer.py", "language": "python", "type": "custom", "uuid": "dt_trainer"}, "custom/enchanting_cloud.py:custom:python:enchanting cloud": {"content": "if 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(*args, **kwargs):\n    print(kwargs['selected_models'])\n    print(type(kwargs['selected_models']))\n    \n\n    return \"test\"\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/enchanting_cloud.py", "language": "python", "type": "custom", "uuid": "enchanting_cloud"}, "custom/exquisite_morning.py:custom:python:exquisite morning": {"content": "import pandas as pd\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, *args, **kwargs):\n    output  = data.iloc[1]\n\n    print(output.to_dict())\n    \n    return output.to_dict()\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/exquisite_morning.py", "language": "python", "type": "custom", "uuid": "exquisite_morning"}, "custom/final_model.py:custom:python:final model": {"content": "@custom\ndef select_best_model(data, data_2, data_3, data_4, data_5, *args, **kwargs):\n    # Get all model results from kwargs.values()\n    search_space = [data, data_2, data_3, data_4, data_5]\n    models = [m for m in search_space if type(m) is not list]\n\n    # Find the model with the lowest RMSE\n    best_model = min(models, key=lambda x: x[\"rmse\"])\n\n    print(f\"Best model: {best_model['model']} with RMSE: {best_model['rmse']}\")\n\n    # Return the best trained model, print model's RMSE, and all model RMSEs\n    print(f\"Best model's performance: {best_model['rmse']}\")\n    print(f\"Other model's perfromance: \", {m[\"model\"]: m[\"rmse\"] for m in models})\n    return best_model[\"trained_model\"]\n", "file_path": "custom/final_model.py", "language": "python", "type": "custom", "uuid": "final_model"}, "custom/knn_trainer.py:custom:python:knn trainer": {"content": "from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, data_2, *args, **kwargs):\n    \n    if \"knn\" not in data_2:\n        # return \"knn model isn't being trained.\"\n        return None\n\n\n    X_train, X_validation, y_train, y_test = data\n\n    knn = GridSearchCV(KNeighborsRegressor(), data_2.get(\"knn\"), cv=5)\n    knn.fit(X_train, y_train)\n    knn_pred = knn.predict(X_validation)\n    knn_rmse = np.sqrt(mean_squared_error(y_test, knn_pred))\n\n\n    return {\"model\": \"knn\", \"rmse\": knn_rmse, \"trained_model\": knn}", "file_path": "custom/knn_trainer.py", "language": "python", "type": "custom", "uuid": "knn_trainer"}, "custom/lasso_trainer.py:custom:python:lasso trainer": {"content": "from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, data_2, *args, **kwargs):\n    \n    if \"lasso\" not in data_2:\n        # return \"lasso model isn't being trained.\"\n        return None\n\n\n    X_train, X_validation, y_train, y_test = data\n\n    lasso = GridSearchCV(Lasso(random_state=0), data_2.get(\"lasso\"), cv=5)\n    lasso.fit(X_train, y_train)\n    lasso_pred = lasso.predict(X_validation)\n    lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso_pred))\n\n    return {\"model\": \"lasso\", \"rmse\": lasso_rmse, \"trained_model\": lasso}", "file_path": "custom/lasso_trainer.py", "language": "python", "type": "custom", "uuid": "lasso_trainer"}, "custom/making_predictions.py:custom:python:making predictions": {"content": "import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef prediction(data, data_2, *args, **kwargs):\n\n    model = data['final_model'][0].best_estimator_\n    \n    if not isinstance(data_2, pd.DataFrame):\n        return \"No data was provided for predictions!\"\n    \n    else: \n        print(\"Generating predections for the provided data...\")\n        ids = data_2.pop('id')\n        preds = model.predict(data_2)\n        predictions = pd.DataFrame({\"id\":ids, \"predictions\":preds})\n        return predictions\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/making_predictions.py", "language": "python", "type": "custom", "uuid": "making_predictions"}, "custom/models_hyperparameters.py:custom:python:models hyperparameters": {"content": "from typing import Optional, List\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n### you can select which model to train by specifying it\n### as a global variable \n### options are: all, lasso, ridge, knn, DecisionTree, RandomForest\n\n\n@custom\ndef transform_custom(option:Optional[List[str]]=None, *args, **kwargs):\n\n    available_models = {\n        \"ridge\" : {\n            \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n        },\n        \"lasso\": {\n            \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n        },\n        \"knn\": {\n            \"n_neighbors\": [3, 5, 7, 9, 11, 13],\n            \"weights\": [\"uniform\", \"distance\"],\n            \"p\": [1, 2]  \n        },\n        \"dt\": {\n            \"max_depth\": [3, 5, 10, 15, 20, None],\n            \"min_samples_split\": [2, 5, 10],\n            \"min_samples_leaf\": [1, 2, 5],\n            \"max_features\": [\"sqrt\", \"log2\", None]\n        },\n        \"rf\": {\n            \"n_estimators\": [50, 100, 200, 500],\n            \"max_depth\": [3, 5, 10, 20, None],\n            \"min_samples_split\": [2, 5, 10],\n            \"min_samples_leaf\": [1, 2, 5],\n            \"max_features\": [\"sqrt\", \"log2\", None],\n            \"bootstrap\": [True, False]\n        }\n\n    }\n\n    if option == []:\n        return available_models\n\n    if option != []:\n        search_space = {}\n        for i in option :\n            search_space[i] = available_models.get(i)\n        return search_space\n    \n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/models_hyperparameters.py", "language": "python", "type": "custom", "uuid": "models_hyperparameters"}, "custom/model_selection.py:custom:python:model selection": {"content": "import ast\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(*args, **kwargs):\n    \n    data = {\n        \"ridge\" : {\n            \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n        },\n        \"lasso\": {\n            \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n        },\n        \"knn\": {\n            \"n_neighbors\": [3, 5, 7, 9, 11, 13],\n            \"weights\": [\"uniform\", \"distance\"],\n            \"p\": [1, 2]  \n        },\n        \"dt\": {\n            \"max_depth\": [3, 5, 10, 15, 20, None],\n            \"min_samples_split\": [2, 5, 10],\n            \"min_samples_leaf\": [1, 2, 5],\n            \"max_features\": [\"sqrt\", \"log2\", None]\n        },\n        \"rf\": {\n            \"n_estimators\": [10, 20, 50],\n            \"max_depth\": [3, 5, 10, 15, None],\n            \"min_samples_split\": [2, 5, 10],\n            \"min_samples_leaf\": [1, 2, 5],\n            \"max_features\": [\"sqrt\", \"log2\", None],\n            \"bootstrap\": [True, False]\n        }\n\n    }\n\n    selected_models = kwargs.get(\"selected_models\", [\"ridge\", \"lasso\", \"knn\", \"dt\", \"rf\"])\n    \n    # Convert string representation of a list to an actual list\n    if isinstance(selected_models, str):\n        try:\n            selected_models = ast.literal_eval(selected_models)\n        except (SyntaxError, ValueError):\n            raise ValueError(f\"Invalid format for selected_models: {selected_models}. Expected a list.\")\n\n    # Ensure it's a list\n    if not isinstance(selected_models, list):\n        raise TypeError(f\"Expected selected_models to be a list, got {type(selected_models)} instead.\")\n\n\n    filtered_models = {model: data[model] for model in selected_models if model in data}\n\n    print(f\"Selected models for training: {list(filtered_models.keys())}\")\n\n    return filtered_models\n\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/model_selection.py", "language": "python", "type": "custom", "uuid": "model_selection"}, "custom/rf_trainer.py:custom:python:rf trainer": {"content": "from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, data_2, *args, **kwargs):\n    \n    if \"rf\" not in data_2:\n        # return \"Random forest model isn't being trained.\"\n        return None\n\n\n    X_train, X_validation, y_train, y_test = data\n\n    rf = GridSearchCV(RandomForestRegressor(random_state=0), data_2.get(\"rf\"), cv=5)\n    rf.fit(X_train, y_train)\n    rf_pred = rf.predict(X_validation)\n    rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n\n\n    return {\"model\": \"rf\", \"rmse\": rf_rmse, \"trained_model\": rf}", "file_path": "custom/rf_trainer.py", "language": "python", "type": "custom", "uuid": "rf_trainer"}, "custom/ridgee_trainer.py:custom:python:ridgee trainer": {"content": "from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, data_2, *args, **kwargs):\n    if \"ridge\" not in data_2:\n        # return \"Ridge model isn't being trained.\"\n        return None\n\n\n    X_train, X_validation, y_train, y_test = data\n\n    ridge = GridSearchCV(Ridge(random_state=0), data_2.get(\"ridge\"), cv=5)\n    ridge.fit(X_train, y_train)\n    ridge_pred = ridge.predict(X_validation)\n    ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_pred))\n\n    return {\"model\": \"ridge\", \"rmse\": ridge_rmse, \"trained_model\": ridge}\n", "file_path": "custom/ridgee_trainer.py", "language": "python", "type": "custom", "uuid": "ridgee_trainer"}, "custom/ridge_trainer.sql:custom:sql:ridge trainer": {"content": "-- Docs: https://docs.mage.ai/guides/sql-blocks\n", "file_path": "custom/ridge_trainer.sql", "language": "sql", "type": "custom", "uuid": "ridge_trainer"}, "custom/test.py:custom:python:test": {"content": "import pandas as pd\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, *args, **kwargs):\n    X_train, X_validation, y_train, y_test = data\n\n    print(X_train.iloc[0].to_dict()) \n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/test.py", "language": "python", "type": "custom", "uuid": "test"}, "custom/training.py:custom:python:training": {"content": "from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nimport mlflow\nfrom datetime import date\n\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n\n# current_date = date.today()\n# mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n# mlflow.set_experiment(f\"Mage training_models {current_date} Pipeline\")\n\n\n\n@custom\ndef transform_custom(data, data_2, *args, **kwargs):\n    rmse_results = {}\n\n    X_train = data_2[0]\n    X_validation = data_2[1]\n    y_train = data_2[2]\n    y_test = data_2[3]\n\n    print(\"Started training...\")\n    for model in data :\n        if model == \"ridge\":\n            ridge = GridSearchCV(Lasso(random_state=0), data.get(model), cv=5)\n            ridge.fit(X_train, y_train)\n            ridge_pred = ridge.predict(X_validation)\n            ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_pred))\n            rmse_results[\"ridge\"] = ridge_rmse\n            print(\"Finished training ridge.\")\n\n        if model == \"lasso\":\n            lasso = GridSearchCV(Ridge(random_state=0), data.get(model), cv=5)\n            lasso.fit(X_train, y_train)\n            lasso_pred = lasso.predict(X_validation)\n            lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso_pred))\n            rmse_results[\"lasso\"] = lasso_rmse\n            print(\"Finished training lasso.\")\n\n        if model == \"knn\":\n            knn = GridSearchCV(KNeighborsRegressor(), data.get(model), cv=5)\n            knn.fit(X_train, y_train)\n            knn_pred = knn.predict(X_validation)\n            knn_rmse = np.sqrt(mean_squared_error(y_test, knn_pred))\n            rmse_results[\"knn\"] = knn_rmse\n            print(\"Finished training KNN.\")\n\n        if model == \"dt\":\n            dt = GridSearchCV(DecisionTreeRegressor(random_state=0), data.get(model), cv=5)\n            dt.fit(X_train, y_train)\n            dt_pred = dt.predict(X_validation)\n            dt_rmse = np.sqrt(mean_squared_error(y_test,dt_pred))\n            rmse_results[\"dt\"] = dt_rmse\n            print(\"Finished training decision tree.\")\n\n        if model ==\"rf\":\n            rf = GridSearchCV(RandomForestRegressor(random_state=0), data.get(model), cv=5)\n            rf.fit(X_train, y_train)\n            rf_pred = dt.predict(X_validation)\n            rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n            rmse_results[\"rf\"] = rf_rmse\n            print(\"Finished training random forest\n            .\")\n\n\n    # with mlflow.start_run(run_name=\"Saving used models, their hyperparameters and RMSE scores\") as run:\n    #     input_example = X_train.iloc[:1]\n    #     for model in data :\n    #         if model == \"ridge\":\n    #             ridge_params = ridge.get_params()\n    #             mlflow.log_params(ridge_params)\n    #             mlflow.sklearn.log_model(ridge, model, input_example=input_example)\n    #         if model == \"lasso\":\n    #             lasso_params = lasso.get_params()\n    #             mlflow.log_params(lasso_params)\n    #             mlflow.sklearn.log_model(lasso, model, input_example=input_example)\n    #         if model == \"knn\":\n    #             knn_params = knn.get_params()\n    #             mlflow.log_params(knn_params)\n    #             mlflow.sklearn.log_model(knn, model, input_example=input_example)\n    #         if model == \"dt\":\n    #             dt_params = dt.best_params_\n    #             mlflow.log_params(dt_params)\n    #             mlflow.sklearn.log_model(dt, model, input_example=input_example)\n    #         if model == \"rf\":\n    #             rfr_params = rf.best_params_\n    #             mlflow.log_params(rfr_params)\n    #             mlflow.sklearn.log_model(rf, model, input_example=input_example)\n        \n                \n    #     mlflow.log_metrics(rmse_results)\n\n    print(\"Finished training...\")\n\n    best_score = min(rmse_results.values()) \n\n    for model in rmse_results : \n        if rmse_results[model] == best_score:\n            best_model = model\n            break\n\n    if best_model == \"ridge\":\n        return ridge, best_score, rmse_results\n    if best_model == \"lasso\":\n        return lasso, best_score, rmse_results\n    if best_model == \"knn\":\n        return knn, best_score, rmse_results\n    if best_model == \"dt\":\n        return dt, best_score, rmse_results\n    if best_model == \"rf\":\n        return rf, best_score, rmse_results\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/training.py", "language": "python", "type": "custom", "uuid": "training"}, "data_exporters/export_titanic_clean.py:data_exporter:python:export titanic clean": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#example-loading-data-from-a-file\n    \"\"\"\n    filepath = 'titanic_clean.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/export_titanic_clean.py", "language": "python", "type": "data_exporter", "uuid": "export_titanic_clean"}, "data_exporters/load_intopostgres.py:data_exporter:python:load intopostgres": {"content": "from mage_ai.settings.repo import get_repo_path\nfrom mage_ai.io.config import ConfigFileLoader\nfrom mage_ai.io.postgres import Postgres\nimport pandas as pd\nfrom os import path\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_postgres(data, **kwargs) -> None:\n\n    if kwargs['export_data'] == \"yes\" : \n\n        X_train, X_validation, y_train, y_test = data\n\n\n        schema_name = 'public'  # Specify the name of the schema to export data to\n        table_name = 'mage_traindata'  # Specify the name of the table to export data to\n        config_path = path.join(get_repo_path(), 'io_config.yaml')\n        config_profile = 'default'\n\n        train_df = pd.concat([X_train, y_train])\n        test_df = pd.concat([X_validation, y_test])\n\n        with Postgres.with_config(ConfigFileLoader(config_path, config_profile)) as loader:\n            loader.export(\n                y_test,\n                schema_name,\n                table_name,\n                index=True,  # Specifies whether to include index in exported table\n                if_exists='replace',  # Specify resolution policy if table name already exists\n            )\n\n        return f\"Saved training dataset to {table_name} table.\"\n\n    else:\n        return f\"Dataset wasn't saved since export_data is set to {kwargs['export_data']}.\"", "file_path": "data_exporters/load_intopostgres.py", "language": "python", "type": "data_exporter", "uuid": "load_intopostgres"}, "data_loaders/loading_data.py:data_loader:python:loading data": {"content": "import io\nimport pandas as pd\nimport requests\nimport os\nimport opendatasets\nimport json\n\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(*args, **kwargs) :\n\n    cwd = os.getcwd()\n    data_dir = kwargs['configuration'].get('download_dir')\n\n    if 'diamonds-prices' in os.listdir(f\"{cwd}/{data_dir}\") :\n        print(\"Data already exists, won't download it.\")\n        df = pd.read_csv(f\"{data_dir}/diamonds-prices/Diamonds Prices2022.csv\", index_col=0)\n        return df\n    \n    else:\n        ### Adding the kaggle.json for kaggle API authentication\n        dir_content  = os.listdir()\n        if 'kaggle.json' not in dir_content : \n            with open(\"kaggle.json\", \"w\") as file:\n                data= {\"username\":kwargs['configuration'].get('username'),\\\n                \"key\":kwargs['configuration'].get('key')}\n                json.dump(data, file)\n\n        print(\"Downloading dataset...\")\n        opendatasets.download_kaggle_dataset(kwargs['configuration'].get('dataset_url'),\\\n        kwargs['configuration'].get('download_dir'))\n\n        df = pd.read_csv(f\"{kwargs['configuration'].get('download_dir')}/diamonds-prices/Diamonds Prices2022.csv\", index_col=0)\n        return df\n\n\n\n@test\ndef test_output(output, *args) -> None:\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/loading_data.py", "language": "python", "type": "data_loader", "uuid": "loading_data"}, "data_loaders/load_data.py:data_loader:python:load data": {"content": "import io\nimport pandas as pd\nimport requests\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(*args, **kwargs):\n    fake_data = {'carat': 0.21, 'cut': 'Premium', 'color': 'E', 'clarity': 'SI1', 'depth': 59.8, 'table': 61.0, 'price': 326, 'x': 3.89, 'y': 3.84, 'z': 2.31}\n    return pd.DataFrame(fake_data, index=[0])\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_data.py", "language": "python", "type": "data_loader", "uuid": "load_data"}, "data_loaders/load_data_pg.py:data_loader:python:load data pg": {"content": "from mage_ai.settings.repo import get_repo_path\nfrom mage_ai.io.config import ConfigFileLoader\nfrom mage_ai.io.postgres import Postgres\nfrom os import path\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_postgres(*args, **kwargs):\n   \n    query = 'SELECT * FROM raw_data;'\n    config_path = path.join(get_repo_path(), 'io_config.yaml')\n    config_profile = 'default'\n\n    with Postgres.with_config(ConfigFileLoader(config_path, config_profile)) as loader:\n        return loader.load(query)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_data_pg.py", "language": "python", "type": "data_loader", "uuid": "load_data_pg"}, "data_loaders/load_titanic.py:data_loader:python:load titanic": {"content": "import io\nimport pandas as pd\nimport requests\nfrom pandas import DataFrame\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(**kwargs) -> DataFrame:\n    \"\"\"\n    Template for loading data from API\n    \"\"\"\n    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv?raw=True'\n\n    return pd.read_csv(url)\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_titanic.py", "language": "python", "type": "data_loader", "uuid": "load_titanic"}, "markdowns/inference_instructions.md:markdown:markdown:inference instructions": {"content": "#### This pipeline is used for making predictions to the diamonds dataset. *(by recieving an API call)* </br> </br>\n###### - It'll load the best model from the training pipeline, load raw_data from a postgres database, clean the data and make predictions.</br></br>\n###### - You can check the predictions/output of this pipeline as shown in the link https://docs.mage.ai/orchestration/pipeline-runs/saving-block-output-as-csv .</br></br>\n", "file_path": "markdowns/inference_instructions.md", "language": "markdown", "type": "markdown", "uuid": "inference_instructions"}, "markdowns/instructions.md:markdown:markdown:instructions": {"content": "#### This pipeline is used for loading the diamonds dataset from opendatasets (kaggle API) </br> </br>\n###### - It'll perform data cleaning, saving cleaned data and model training.</br></br>\n###### - You can choose if you'd like to save the cleaned dataset to postgres database by specifying the value of the global variable *export_data* it has either yes, no by default it's yes.</br></br>\n###### - You can choose which models to train by providing them in the global variable *selected_models* in this format [\"dt\",\"knn\"]. </br></br>\n", "file_path": "markdowns/instructions.md", "language": "markdown", "type": "markdown", "uuid": "instructions"}, "transformers/clean_data.py:transformer:python:clean data": {"content": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom typing import Optional, Tuple\nfrom sklearn.preprocessing import OrdinalEncoder\n\n\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\ndef removenull(df:pd.DataFrame) -> pd.DataFrame:\n    \n    ### Removing NaN\n    df.dropna(inplace=True)\n\n    ### Removing 0 values\n    df = df[(df != 0).all(axis=1)]\n\n    return df\n\ndef encodeCats(df:pd.DataFrame) -> pd.DataFrame:\n    \n    encoder_cut = OrdinalEncoder(categories=[[\"Fair\",\"Good\",\"Very Good\",\"Premium\",\"Ideal\"]], handle_unknown='use_encoded_value', unknown_value = 100).fit(df[[\"cut\"]])\n    encoded_cut = encoder_cut.transform(df[[\"cut\"]])\n\n    encoder_color = OrdinalEncoder(categories=[[\"J\",\"I\",\"H\",\"G\",\"F\",\"E\",\"D\"]],  handle_unknown='use_encoded_value', unknown_value = 100).fit(df[[\"color\"]])\n    encoded_color = encoder_color.transform(df[[\"color\"]])\n\n    encoder_clarity = OrdinalEncoder(categories=[[\"I1\",\"SI2\",\"SI1\",\"VS2\",\"VS1\",\"VVS2\",\"VVS1\",\"IF\"]],  handle_unknown='use_encoded_value', unknown_value = 100).fit(df[[\"clarity\"]])\n    encoded_clarity = encoder_clarity.transform(df[[\"clarity\"]])\n\n    df[\"cut\"] = encoded_cut\n    df[\"color\"] = encoded_color\n    df[\"clarity\"] = encoded_clarity\n\n    df[['cut','color','clarity']] = df[['cut','color','clarity']].replace(100, 0)\n\n    return df\n\ndef newFeatures(df:pd.DataFrame) -> pd.DataFrame:\n\n    df[\"total_depth\"] = (df[\"z\"]*2)/(df[\"x\"]+df[\"y\"])\n    df[\"size\"] = df[\"x\"] * df[\"y\"] * df[\"z\"]\n\n    df = df.drop([\"x\",\"y\",\"z\"],axis=1)\n\n    return df\n\n@transformer\ndef transform(data, *args, **kwargs) -> pd.DataFrame:\n    \n    cleaned_data = encodeCats(newFeatures(removenull(data)))\n    \n    return cleaned_data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/clean_data.py", "language": "python", "type": "transformer", "uuid": "clean_data"}, "transformers/fill_in_missing_values.py:transformer:python:fill in missing values": {"content": "from pandas import DataFrame\nimport math\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\ndef select_number_columns(df: DataFrame) -> DataFrame:\n    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n\n\ndef fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n    for col in df.columns:\n        values = sorted(df[col].dropna().tolist())\n        median_value = values[math.floor(len(values) / 2)]\n        df[[col]] = df[[col]].fillna(median_value)\n    return df\n\n\n@transformer\ndef transform_df(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        df (DataFrame): Data frame from parent block.\n\n    Returns:\n        DataFrame: Transformed data frame\n    \"\"\"\n    # Specify your transformation logic here\n\n    return fill_missing_values_with_median(select_number_columns(df))\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "transformers/fill_in_missing_values.py", "language": "python", "type": "transformer", "uuid": "fill_in_missing_values"}, "transformers/model_training.py:transformer:python:model training": {"content": "from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nimport mlflow\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(data, data_2):\n    \n    rmse_results = {}\n\n    X_train = data_2[0]\n    X_validation = data_2[1]\n    y_train = data_2[2]\n    y_test = data_2[3]\n\n    for model in data :\n        if model == \"ridge\":\n            ridge = GridSearchCV(Lasso(random_state=0), data.get(model), cv=5)\n            ridge.fit(X_train, y_train)\n            ridge_pred = ridge.predict(X_validation)\n            ridge_rmse = np.sqrt(mean_squared_error(y_validation,ridge_pred))\n            rmse_results[\"ridge\"] = ridge_rmse\n\n        if model == \"lasso\":\n            lasso = GridSearchCV(Ridge(random_state=0), data.get(model), cv=5)\n            lasso.fit(X_train, y_train)\n            lasso_pred = lasso.predict(X_validation)\n            lasso_rmse = np.sqrt(mean_squared_error(y_validation,lasso_pred))\n            rmse_results[\"lasso\"] = lasso_rmse\n\n        if model == \"knn\":\n            knn = GridSearchCV(KNeighborsRegressor(), data.get(model), cv=5)\n            knn.fit(X_train, y_train)\n            knn_pred = knn.predict(X_validation)\n            knn_rmse = np.sqrt(mean_squared_error(y_validation,knn_pred))\n            rmse_results[\"knn\"] = knn_rmse\n\n        if model == \"dt\":\n            dt = GridSearchCV(DecisionTreeRegressor(random_state=0), data.get(model), cv=5)\n            dt.fit(X_train, y_train)\n            dt_pred = dt.predict(X_validation)\n            dt_rmse = np.sqrt(mean_squared_error(y_validation,dt_pred))\n            rmse_results[\"dt\"] = dt_rmse\n\n        if model ==\"rf\":\n            rf = GridSearchCV(RandomForestRegressor(random_state=0), data.get(model), cv=5)\n            rf.fit(X_train, y_train)\n            rf_pred = dt.predict(X_validation)\n            rf_rmse = np.sqrt(mean_squared_error(y_validation,rf_pred))\n            rmse_results[\"rf\"] = rf_rmse\n\n\n    return rmse_results\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/model_training.py", "language": "python", "type": "transformer", "uuid": "model_training"}, "transformers/preprocessing_data.py:transformer:python:preprocessing data": {"content": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom typing import Optional, Tuple\nfrom sklearn.preprocessing import OrdinalEncoder\n\n\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\ndef removenull(df:pd.DataFrame) -> pd.DataFrame:\n    \n    ### Removing NaN\n    df.dropna(inplace=True)\n\n    ### Removing 0 values\n    df = df[(df != 0).all(axis=1)]\n\n    return df\n\ndef splitData(df:pd.DataFrame, test_size:Optional[float]=0.2) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n\n    X = df.drop(\"price\",axis=1)\n    y = df[\"price\"]\n\n    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=test_size, random_state=0)\n    \n    return X_train, X_validation, y_train, y_validation\n\ndef fixOutliers(df:pd.DataFrame) -> pd.DataFrame :\n\n    cols = ['carat', 'depth','table','total_depth','size'] \n\n    Q1 = df[cols].quantile(0.25)\n    Q3 = df[cols].quantile(0.75)\n    IQR = Q3 - Q1\n\n    df = df[~(( df[cols] < (Q1 - 1.5 * IQR)) |( df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n\n    return df\n\ndef encodeCats(df:pd.DataFrame) -> pd.DataFrame:\n    \n    encoder_cut = OrdinalEncoder(categories=[[\"Fair\",\"Good\",\"Very Good\",\"Premium\",\"Ideal\"]], handle_unknown='use_encoded_value', unknown_value = 100).fit(df[[\"cut\"]])\n    encoded_cut = encoder_cut.transform(df[[\"cut\"]])\n\n    encoder_color = OrdinalEncoder(categories=[[\"J\",\"I\",\"H\",\"G\",\"F\",\"E\",\"D\"]],  handle_unknown='use_encoded_value', unknown_value = 100).fit(df[[\"color\"]])\n    encoded_color = encoder_color.transform(df[[\"color\"]])\n\n    encoder_clarity = OrdinalEncoder(categories=[[\"I1\",\"SI2\",\"SI1\",\"VS2\",\"VS1\",\"VVS2\",\"VVS1\",\"IF\"]],  handle_unknown='use_encoded_value', unknown_value = 100).fit(df[[\"clarity\"]])\n    encoded_clarity = encoder_clarity.transform(df[[\"clarity\"]])\n\n    df[\"cut\"] = encoded_cut\n    df[\"color\"] = encoded_color\n    df[\"clarity\"] = encoded_clarity\n\n    df[['cut','color','clarity']] = df[['cut','color','clarity']].replace(100, 0)\n\n    return df\n\ndef newFeatures(df:pd.DataFrame) -> pd.DataFrame:\n\n    df[\"total_depth\"] = (df[\"z\"]*2)/(df[\"x\"]+df[\"y\"])\n    df[\"size\"] = df[\"x\"] * df[\"y\"] * df[\"z\"]\n\n    df = df.drop([\"x\",\"y\",\"z\"],axis=1)\n\n    return df\n\n@transformer\ndef transform(data, *args, **kwargs) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n    \n    cleaned_data = encodeCats(fixOutliers(newFeatures(removenull(data))))\n\n    X_train, X_validation, y_train, y_validation = splitData(cleaned_data)\n    \n    return (X_train, X_validation, y_train, y_validation)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/preprocessing_data.py", "language": "python", "type": "transformer", "uuid": "preprocessing_data"}, "transformers/select_model.py:transformer:python:select model": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(*args, **kwargs) :\n\n    ### select which model to train, if none is selected all available models will be trained\n    ## return a list of models names\n\n    option  = [\"lasso\", \"ridge\", \"dt\", \"knn\", \"rf\"]\n\n    option = []\n\n    return option\n\n", "file_path": "transformers/select_model.py", "language": "python", "type": "transformer", "uuid": "select_model"}, "pipelines/inference/metadata.yaml:pipeline:yaml:inference/metadata": {"content": "blocks:\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: markdown\n  name: Inference Instructions\n  retry_config: null\n  status: updated\n  timeout: null\n  type: markdown\n  upstream_blocks: []\n  uuid: inference_instructions\n- all_upstream_blocks_executed: true\n  color: null\n  configuration:\n    file_path: global_data_products/load_model.py\n    file_source:\n      path: null\n    global_data_product:\n      uuid: best_model_after_training\n  downstream_blocks:\n  - making_predictions\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: load_model\n  retry_config: null\n  status: executed\n  timeout: null\n  type: global_data_product\n  upstream_blocks: []\n  uuid: load_model\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks:\n  - clean_data\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: load_data_pg\n  retry_config: null\n  status: executed\n  timeout: null\n  type: data_loader\n  upstream_blocks: []\n  uuid: load_data_pg\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks:\n  - making_predictions\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: clean_data\n  retry_config: null\n  status: executed\n  timeout: null\n  type: transformer\n  upstream_blocks:\n  - load_data_pg\n  uuid: clean_data\n- all_upstream_blocks_executed: true\n  color: yellow\n  configuration:\n    file_path: custom/making_predictions.py\n    file_source:\n      path: custom/making_predictions.py\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: making_predictions\n  retry_config: null\n  status: updated\n  timeout: null\n  type: custom\n  upstream_blocks:\n  - load_model\n  - clean_data\n  uuid: making_predictions\ncache_block_output_in_memory: false\ncallbacks: []\nconcurrency_config: {}\nconditionals: []\ncreated_at: '2025-02-01 09:47:47.978685+00:00'\ndata_integration: null\ndescription: Inferencing by using the best model that was outputted from the training\n  pipeline.\nexecutor_config: {}\nexecutor_count: 1\nexecutor_type: null\nextensions: {}\nname: inference\nnotification_config: {}\nremote_variables_dir: null\nretry_config: {}\nrun_pipeline_in_one_process: false\nsettings:\n  triggers: null\nspark_config: {}\ntags: []\ntype: python\nuuid: inference\nvariables_dir: /home/src/mage_data/[training]\nwidgets: []\n", "file_path": "pipelines/inference/metadata.yaml", "language": "yaml", "type": "pipeline", "uuid": "inference/metadata"}, "pipelines/inference/triggers.yaml:pipeline:yaml:inference/triggers": {"content": "triggers:\n- description: null\n  envs: []\n  last_enabled_at: 2025-02-07 17:55:06.174934\n  name: create_predictions\n  pipeline_uuid: inference\n  schedule_interval: null\n  schedule_type: api\n  settings: null\n  sla: null\n  start_time: 2025-02-05 19:48:00\n  status: active\n  token: e40a25717d114dc490126c815b472d4c\n  variables: {}\n", "file_path": "pipelines/inference/triggers.yaml", "language": "yaml", "type": "pipeline", "uuid": "inference/triggers"}, "pipelines/inference/__init__.py:pipeline:python:inference/  init  ": {"content": "", "file_path": "pipelines/inference/__init__.py", "language": "python", "type": "pipeline", "uuid": "inference/__init__"}, "pipelines/training_models/metadata.yaml:pipeline:yaml:training models/metadata": {"content": "blocks:\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: markdown\n  name: Instructions\n  retry_config: null\n  status: updated\n  timeout: null\n  type: markdown\n  upstream_blocks: []\n  uuid: instructions\n- all_upstream_blocks_executed: true\n  color: null\n  configuration:\n    dataset_url: nancyalaswad90/diamonds-prices\n    download_dir: training/\n    key: 04d7f003142f6e627439760f1a63649d\n    username: farahmasri\n  downstream_blocks:\n  - preprocessing_data\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: loading_data\n  retry_config: {}\n  status: executed\n  timeout: null\n  type: data_loader\n  upstream_blocks: []\n  uuid: loading_data\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks:\n  - lasso_trainer\n  - knn_trainer\n  - rf_trainer\n  - dt_trainer\n  - ridgee_trainer\n  - load_intopostgres\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: preprocessing_data\n  retry_config: null\n  status: executed\n  timeout: null\n  type: transformer\n  upstream_blocks:\n  - loading_data\n  uuid: preprocessing_data\n- all_upstream_blocks_executed: true\n  color: pink\n  configuration: {}\n  downstream_blocks:\n  - lasso_trainer\n  - knn_trainer\n  - rf_trainer\n  - dt_trainer\n  - ridgee_trainer\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: model_selection\n  retry_config: null\n  status: executed\n  timeout: null\n  type: custom\n  upstream_blocks: []\n  uuid: model_selection\n- all_upstream_blocks_executed: true\n  color: teal\n  configuration: {}\n  downstream_blocks:\n  - final_model\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: lasso_trainer\n  retry_config: null\n  status: updated\n  timeout: null\n  type: custom\n  upstream_blocks:\n  - preprocessing_data\n  - model_selection\n  uuid: lasso_trainer\n- all_upstream_blocks_executed: true\n  color: teal\n  configuration: {}\n  downstream_blocks:\n  - final_model\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: knn_trainer\n  retry_config: null\n  status: executed\n  timeout: null\n  type: custom\n  upstream_blocks:\n  - preprocessing_data\n  - model_selection\n  uuid: knn_trainer\n- all_upstream_blocks_executed: true\n  color: teal\n  configuration: {}\n  downstream_blocks:\n  - final_model\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: rf_trainer\n  retry_config: null\n  status: executed\n  timeout: null\n  type: custom\n  upstream_blocks:\n  - preprocessing_data\n  - model_selection\n  uuid: rf_trainer\n- all_upstream_blocks_executed: true\n  color: teal\n  configuration: {}\n  downstream_blocks:\n  - final_model\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: dt_trainer\n  retry_config: null\n  status: executed\n  timeout: null\n  type: custom\n  upstream_blocks:\n  - preprocessing_data\n  - model_selection\n  uuid: dt_trainer\n- all_upstream_blocks_executed: true\n  color: teal\n  configuration: {}\n  downstream_blocks:\n  - final_model\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: ridgee_trainer\n  retry_config: null\n  status: executed\n  timeout: null\n  type: custom\n  upstream_blocks:\n  - preprocessing_data\n  - model_selection\n  uuid: ridgee_trainer\n- all_upstream_blocks_executed: false\n  color: yellow\n  configuration: {}\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: final_model\n  retry_config: null\n  status: executed\n  timeout: null\n  type: custom\n  upstream_blocks:\n  - lasso_trainer\n  - knn_trainer\n  - rf_trainer\n  - dt_trainer\n  - ridgee_trainer\n  uuid: final_model\n- all_upstream_blocks_executed: true\n  color: null\n  configuration:\n    file_path: data_exporters/load_intopostgres.py\n    file_source:\n      path: data_exporters/load_intopostgres.py\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: load_intoPostgres\n  retry_config: null\n  status: executed\n  timeout: null\n  type: data_exporter\n  upstream_blocks:\n  - preprocessing_data\n  uuid: load_intopostgres\ncache_block_output_in_memory: false\ncallbacks: []\nconcurrency_config: {}\nconditionals: []\ncreated_at: '2025-01-30 16:59:55.077875+00:00'\ndata_integration: null\ndescription: Train multiple models, save cleaned data. Check the markdown cell in\n  the pipeline.\nexecutor_config: {}\nexecutor_count: 1\nexecutor_type: null\nextensions: {}\nname: training models\nnotification_config: {}\nremote_variables_dir: null\nretry_config: {}\nrun_pipeline_in_one_process: false\nsettings:\n  triggers: null\nspark_config: {}\ntags: []\ntype: python\nuuid: training_models\nvariables:\n  export_data: 'no'\n  selected_models:\n  - dt\n  - knn\nvariables_dir: /home/src/mage_data/[training]\nwidgets: []\n", "file_path": "pipelines/training_models/metadata.yaml", "language": "yaml", "type": "pipeline", "uuid": "training_models/metadata"}, "pipelines/training_models/triggers.yaml:pipeline:yaml:training models/triggers": {"content": "triggers:\n- description: null\n  envs: []\n  last_enabled_at: 2025-02-01 10:22:49.323719\n  name: Run training pipeline once\n  pipeline_uuid: training_models\n  schedule_interval: '@once'\n  schedule_type: time\n  settings: null\n  sla: null\n  start_time: 2025-01-31 09:12:00\n  status: inactive\n  token: d15d488a880545a3a9900ed933070727\n  variables:\n    export_data: 'no'\n    selected_models:\n    - lasso\n    - knn\n", "file_path": "pipelines/training_models/triggers.yaml", "language": "yaml", "type": "pipeline", "uuid": "training_models/triggers"}, "pipelines/training_models/__init__.py:pipeline:python:training models/  init  ": {"content": "", "file_path": "pipelines/training_models/__init__.py", "language": "python", "type": "pipeline", "uuid": "training_models/__init__"}}, "custom_block_template": {}, "mage_template": {"data_loaders/deltalake/s3.py:data_loader:python:Amazon S3:Load a Delta Table from Amazon S3.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_loaders/deltalake/s3.py"}, "data_loaders/deltalake/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Load a Delta Table from Azure Blob Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/deltalake/azure_blob_storage.py"}, "data_loaders/deltalake/gcs.py:data_loader:python:Google Cloud Storage:Load a Delta Table from Google Cloud Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/deltalake/gcs.py"}, "data_loaders/mongodb.py:data_loader:python:MongoDB:Load data from MongoDB.:Databases (NoSQL)": {"block_type": "data_loader", "description": "Load data from MongoDB.", "groups": ["Databases (NoSQL)"], "language": "python", "name": "MongoDB", "path": "data_loaders/mongodb.py"}, "data_loaders/mssql.py:data_loader:python:MSSQL:Load data from MSSQL.:Databases": {"block_type": "data_loader", "description": "Load data from MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_loaders/mssql.py"}, "data_exporters/deltalake/s3.py:data_exporter:python:Amazon S3:Export data to a Delta Table in Amazon S3.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_exporters/deltalake/s3.py"}, "data_exporters/deltalake/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Export data to a Delta Table in Azure Blob Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/deltalake/azure_blob_storage.py"}, "data_exporters/deltalake/gcs.py:data_exporter:python:Google Cloud Storage:Export data to a Delta Table in Google Cloud Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/deltalake/gcs.py"}, "data_exporters/mongodb.py:data_exporter:python:MongoDB:Export data to MongoDB.": {"block_type": "data_exporter", "description": "Export data to MongoDB.", "language": "python", "name": "MongoDB", "path": "data_exporters/mongodb.py"}, "data_exporters/mssql.py:data_exporter:python:MSSQL:Export data to MSSQL.:Databases": {"block_type": "data_exporter", "description": "Export data to MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_exporters/mssql.py"}, "data_loaders/orchestration/triggers/default.jinja:data_loader:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_loader", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_loaders/orchestration/triggers/default.jinja"}, "data_exporters/orchestration/triggers/default.jinja:data_exporter:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_exporter", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_exporters/orchestration/triggers/default.jinja"}, "callbacks/base.jinja:callback:python:Base template:Base template with empty functions.": {"block_type": "callback", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "callbacks/base.jinja"}, "callbacks/orchestration/triggers/default.jinja:callback:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "callback", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "callbacks/orchestration/triggers/default.jinja"}, "conditionals/base.jinja:conditional:python:Base template:Base template with empty functions.": {"block_type": "conditional", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "conditionals/base.jinja"}, "data_loaders/default.jinja:data_loader:python:Base template (generic)": {"block_type": "data_loader", "language": "python", "name": "Base template (generic)", "path": "data_loaders/default.jinja"}, "data_loaders/s3.py:data_loader:python:Amazon S3:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_loaders/s3.py"}, "data_loaders/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/azure_blob_storage.py"}, "data_loaders/google_cloud_storage.py:data_loader:python:Google Cloud Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/google_cloud_storage.py"}, "data_loaders/redshift.py:data_loader:python:Amazon Redshift:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_loaders/redshift.py"}, "data_loaders/bigquery.py:data_loader:python:Google BigQuery:Load data from Google BigQuery.:Data warehouses": {"block_type": "data_loader", "description": "Load data from Google BigQuery.", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_loaders/bigquery.py"}, "data_loaders/snowflake.py:data_loader:python:Snowflake:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_loaders/snowflake.py"}, "data_loaders/algolia.py:data_loader:python:Algolia:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_loaders/algolia.py"}, "data_loaders/chroma.py:data_loader:python:Chroma:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_loaders/chroma.py"}, "data_loaders/duckdb.py:data_loader:python:DuckDB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_loaders/duckdb.py"}, "data_loaders/mysql.py:data_loader:python:MySQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_loaders/mysql.py"}, "data_loaders/oracledb.py:data_loader:python:Oracle DB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Oracle DB", "path": "data_loaders/oracledb.py"}, "data_loaders/postgres.py:data_loader:python:PostgreSQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_loaders/postgres.py"}, "data_loaders/qdrant.py:data_loader:python:Qdrant:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_loaders/qdrant.py"}, "data_loaders/weaviate.py:data_loader:python:Weaviate:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_loaders/weaviate.py"}, "data_loaders/api.py:data_loader:python:API:Fetch data from an API request.": {"block_type": "data_loader", "description": "Fetch data from an API request.", "language": "python", "name": "API", "path": "data_loaders/api.py"}, "data_loaders/file.py:data_loader:python:Local file:Load data from a file on your machine.": {"block_type": "data_loader", "description": "Load data from a file on your machine.", "language": "python", "name": "Local file", "path": "data_loaders/file.py"}, "data_loaders/google_sheets.py:data_loader:python:Google Sheets:Load data from a worksheet in Google Sheets.": {"block_type": "data_loader", "description": "Load data from a worksheet in Google Sheets.", "language": "python", "name": "Google Sheets", "path": "data_loaders/google_sheets.py"}, "data_loaders/druid.py:data_loader:python:Druid": {"block_type": "data_loader", "language": "python", "name": "Druid", "path": "data_loaders/druid.py"}, "transformers/default.jinja:transformer:python:Base template (generic)": {"block_type": "transformer", "language": "python", "name": "Base template (generic)", "path": "transformers/default.jinja"}, "transformers/data_warehouse_transformer.jinja:transformer:python:Amazon Redshift:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "redshift", "data_source_handler": "Redshift"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Google BigQuery:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "", "data_source": "bigquery", "data_source_handler": "BigQuery"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Snowflake:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "snowflake", "data_source_handler": "Snowflake"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:PostgreSQL:Databases": {"block_type": "transformer", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "postgres", "data_source_handler": "Postgres"}}, "transformers/transformer_actions/row/drop_duplicate.py:transformer:python:Drop duplicate rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Drop duplicate rows", "path": "transformers/transformer_actions/row/drop_duplicate.py"}, "transformers/transformer_actions/row/filter.py:transformer:python:Filter rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Filter rows", "path": "transformers/transformer_actions/row/filter.py"}, "transformers/transformer_actions/row/remove.py:transformer:python:Remove rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Remove rows", "path": "transformers/transformer_actions/row/remove.py"}, "transformers/transformer_actions/row/sort.py:transformer:python:Sort rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Sort rows", "path": "transformers/transformer_actions/row/sort.py"}, "transformers/transformer_actions/column/average.py:transformer:python:Average value of column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Average value of column", "path": "transformers/transformer_actions/column/average.py"}, "transformers/transformer_actions/column/count_distinct.py:transformer:python:Count unique values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Count unique values in column", "path": "transformers/transformer_actions/column/count_distinct.py"}, "transformers/transformer_actions/column/first.py:transformer:python:First value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "First value in column", "path": "transformers/transformer_actions/column/first.py"}, "transformers/transformer_actions/column/last.py:transformer:python:Last value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Last value in column", "path": "transformers/transformer_actions/column/last.py"}, "transformers/transformer_actions/column/max.py:transformer:python:Maximum value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Maximum value in column", "path": "transformers/transformer_actions/column/max.py"}, "transformers/transformer_actions/column/median.py:transformer:python:Median value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Median value in column", "path": "transformers/transformer_actions/column/median.py"}, "transformers/transformer_actions/column/min.py:transformer:python:Min value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Min value in column", "path": "transformers/transformer_actions/column/min.py"}, "transformers/transformer_actions/column/sum.py:transformer:python:Sum of all values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Sum of all values in column", "path": "transformers/transformer_actions/column/sum.py"}, "transformers/transformer_actions/column/count.py:transformer:python:Total count of values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Total count of values in column", "path": "transformers/transformer_actions/column/count.py"}, "transformers/transformer_actions/column/clean_column_name.py:transformer:python:Clean column name:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Clean column name", "path": "transformers/transformer_actions/column/clean_column_name.py"}, "transformers/transformer_actions/column/fix_syntax_errors.py:transformer:python:Fix syntax errors:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Fix syntax errors", "path": "transformers/transformer_actions/column/fix_syntax_errors.py"}, "transformers/transformer_actions/column/reformat.py:transformer:python:Reformat values in column:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Reformat values in column", "path": "transformers/transformer_actions/column/reformat.py"}, "transformers/transformer_actions/column/select.py:transformer:python:Keep column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Keep column(s)", "path": "transformers/transformer_actions/column/select.py"}, "transformers/transformer_actions/column/remove.py:transformer:python:Remove column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Remove column(s)", "path": "transformers/transformer_actions/column/remove.py"}, "transformers/transformer_actions/column/shift_down.py:transformer:python:Shift row values down:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values down", "path": "transformers/transformer_actions/column/shift_down.py"}, "transformers/transformer_actions/column/shift_up.py:transformer:python:Shift row values up:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values up", "path": "transformers/transformer_actions/column/shift_up.py"}, "transformers/transformer_actions/column/normalize.py:transformer:python:Normalize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Normalize data", "path": "transformers/transformer_actions/column/normalize.py"}, "transformers/transformer_actions/column/standardize.py:transformer:python:Standardize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Standardize data", "path": "transformers/transformer_actions/column/standardize.py"}, "transformers/transformer_actions/column/impute.py:transformer:python:Fill in missing values:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Fill in missing values", "path": "transformers/transformer_actions/column/impute.py"}, "transformers/transformer_actions/column/remove_outliers.py:transformer:python:Remove outliers:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Remove outliers", "path": "transformers/transformer_actions/column/remove_outliers.py"}, "transformers/transformer_actions/column/diff.py:transformer:python:Calculate difference between values:Column actions:Feature extraction": {"block_type": "transformer", "groups": ["Column actions", "Feature extraction"], "language": "python", "name": "Calculate difference between values", "path": "transformers/transformer_actions/column/diff.py"}, "data_exporters/default.jinja:data_exporter:python:Base template (generic)": {"block_type": "data_exporter", "language": "python", "name": "Base template (generic)", "path": "data_exporters/default.jinja"}, "data_exporters/file.py:data_exporter:python:Local file": {"block_type": "data_exporter", "language": "python", "name": "Local file", "path": "data_exporters/file.py"}, "data_exporters/google_sheets.py:data_exporter:python:Google Sheets": {"block_type": "data_exporter", "language": "python", "name": "Google Sheets", "path": "data_exporters/google_sheets.py"}, "data_exporters/s3.py:data_exporter:python:Amazon S3:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_exporters/s3.py"}, "data_exporters/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/azure_blob_storage.py"}, "data_exporters/google_cloud_storage.py:data_exporter:python:Google Cloud Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/google_cloud_storage.py"}, "data_exporters/redshift.py:data_exporter:python:Amazon Redshift:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_exporters/redshift.py"}, "data_exporters/bigquery.py:data_exporter:python:Google BigQuery:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_exporters/bigquery.py"}, "data_exporters/snowflake.py:data_exporter:python:Snowflake:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_exporters/snowflake.py"}, "data_exporters/algolia.py:data_exporter:python:Algolia:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_exporters/algolia.py"}, "data_exporters/chroma.py:data_exporter:python:Chroma:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_exporters/chroma.py"}, "data_exporters/duckdb.py:data_exporter:python:DuckDB:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_exporters/duckdb.py"}, "data_exporters/mysql.py:data_exporter:python:MySQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_exporters/mysql.py"}, "data_exporters/oracledb.py:data_exporter:python:OracleDB:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "OracleDB", "path": "data_exporters/oracledb.py"}, "data_exporters/postgres.py:data_exporter:python:PostgreSQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_exporters/postgres.py"}, "data_exporters/qdrant.py:data_exporter:python:Qdrant:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_exporters/qdrant.py"}, "data_exporters/weaviate.py:data_exporter:python:Weaviate:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_exporters/weaviate.py"}, "sensors/default.py:sensor:python:Base template (generic)": {"block_type": "sensor", "language": "python", "name": "Base template (generic)", "path": "sensors/default.py"}, "sensors/s3.py:sensor:python:Amazon S3:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "sensors/s3.py"}, "sensors/google_cloud_storage.py:sensor:python:Google Cloud Storage:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "sensors/google_cloud_storage.py"}, "sensors/redshift.py:sensor:python:Amazon Redshift:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "sensors/redshift.py"}, "sensors/bigquery.py:sensor:python:Google BigQuery:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "sensors/bigquery.py"}, "sensors/snowflake.py:sensor:python:Snowflake:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "sensors/snowflake.py"}, "sensors/mysql.py:sensor:python:MySQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "sensors/mysql.py"}, "sensors/postgres.py:sensor:python:PostgreSQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "sensors/postgres.py"}}}